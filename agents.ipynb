{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import Tool, tool, load_tools, initialize_agent, AgentType, AgentExecutor\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
    "from langchain.docstore import Wikipedia\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools.render import render_text_description, format_tool_to_openai_function\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.schema.agent import AgentFinish, AgentAction\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gpt3_5 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain has some easy Tool wrappers for some tools\n",
    "google = GoogleSerperAPIWrapper()\n",
    "google_tool = Tool.from_function(\n",
    "  func=google.run,\n",
    "  name=\"Google\",\n",
    "  description=\"useful for when you need search for something you are not sure about\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using decorator\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "  \"\"\"Returns the length of a word.\"\"\"\n",
    "  return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support for multi input data structures\n",
    "class Word(BaseModel):\n",
    "  word: str = Field()\n",
    "  strategy: str = Field()\n",
    "  \n",
    "def word_length(word: str, strategy: str) -> int:\n",
    "  return len(word) if strategy == \"normal\" else len(word) * 2\n",
    "\n",
    "word_tool = StructuredTool.from_function(\n",
    "  func=word_length,\n",
    "  name=\"Word_Length_Calculator\",\n",
    "  description=\"useful to calculate the length of a word. use strategy='normal' for normal length, strategy='turbo' for turbo length.\",\n",
    "  args_schema=Word\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolNameTool(BaseTool):\n",
    "  name = \"cool_name\"\n",
    "  description = \"useful to determine if a name is cool\"\n",
    "  \n",
    "  def _run(self, query: str) -> str:\n",
    "    return \"Yes, this is a cool name\" if query == \"Brian\" else \"No, this is not a cool name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  Tool(\n",
    "    name=\"Search\",\n",
    "    func=google.run,\n",
    "    description=\"useful for when you need information about current events and data\"\n",
    "  ),\n",
    "  word_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way to create tool from custom function\n",
    "Tool.from_function(\n",
    "  func=google.run,\n",
    "  name=\"Search\",\n",
    "  description=\"useful for when you need to search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Search: useful for when you need information about current events and data\\nWord_Length_Calculator: Returns the length of a word.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_text_description(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Every agent type in `langchain` has different characteristics, but they mainly differ in what prompt they are using and how they determine what tools to use. It will use either `ReAct` from langchain or `OpenAI` to manage tool invocations. We will first look at the available `off-the-shelf agent` options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot ReAct\n",
    "Uses the ReAct framework to determine which tool to use based solely on the tool's description. A very general purpose action agent. ONLY supports tools with single string input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UJmtg2hKTyvHDdX3Zwq7S5euRSxD\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702236595,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I need to calculate 25 to the power of 0.43.\\nAction: Calculator\\nAction Input: 25 ^ 0.43\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 152,\n",
      "    \"completion_tokens\": 29,\n",
      "    \"total_tokens\": 181\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate 25 to the power of 0.43.\n",
      "Action: Calculator\n",
      "Action Input: 25 ^ 0.43\u001b[0m{\n",
      "  \"id\": \"chatcmpl-8UJmvGO3a3UxFW7U5EQ5s18HWBmpt\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702236597,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"```text\\n25 ** 0.43\\n```\\n...numexpr.evaluate(\\\"25 ** 0.43\\\")...\\n\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 206,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 231\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
      "Thought:{\n",
      "  \"id\": \"chatcmpl-8UJmwgZ2CNz3DPNpeqc7DpgYWK5bv\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702236598,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I now know the final answer\\nFinal Answer: 3.991298452658078\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 197,\n",
      "    \"completion_tokens\": 18,\n",
      "    \"total_tokens\": 215\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 3.991298452658078\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.991298452658078'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can load builtin tools from langchain.agents\n",
    "tools = load_tools([\"llm-math\"], gpt3_5)\n",
    "# will create simple AgentExecutor (no prompt or pipeline)\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"What is 25 to the power of 0.43 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Input ReAct (Structured Chat)\n",
    "\n",
    "Just like zero-shot but supports multi-input tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "Word Length Calculator: Word Length Calculator(word: str, strategy: str) -> int - useful to calculate the length of a word. use strategy='normal' for normal length, strategy='turbo' for turbo length., args: {'word': {'title': 'Word', 'type': 'string'}, 'strategy': {'title': 'Strategy', 'type': 'string'}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or Word Length Calculator\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n",
      "Human: {input}\n",
      "\n",
      "{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UM1BWtTWSvjJB0v8mr5q4O1FK4iI\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702245169,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I can use the Word Length Calculator tool to determine the length of the word 'boulder'. Let me do that for you.\\nAction:```{\\\"action\\\": \\\"Word Length Calculator\\\", \\\"action_input\\\": {\\\"word\\\": \\\"boulder\\\", \\\"strategy\\\": \\\"normal\\\"}}```\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 323,\n",
      "    \"completion_tokens\": 55,\n",
      "    \"total_tokens\": 378\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI can use the Word Length Calculator tool to determine the length of the word 'boulder'. Let me do that for you.\n",
      "Action:```{\"action\": \"Word Length Calculator\", \"action_input\": {\"word\": \"boulder\", \"strategy\": \"normal\"}}```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m7\u001b[0m\n",
      "Thought:{\n",
      "  \"id\": \"chatcmpl-8UM1E4LI69JKU1raY5rLX15ik6oeO\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702245172,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The length of the word 'boulder' is 7.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 412,\n",
      "    \"completion_tokens\": 13,\n",
      "    \"total_tokens\": 425\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThe length of the word 'boulder' is 7.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The length of the word 'boulder' is 7.\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [word_tool]\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.format(agent_scratchpad=\"{agent_scratchpad}\", input=\"{input}\"))\n",
    "agent.run(\"What is the length of the word 'boulder'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "This agent will let OpenAI make the decision on what tool to use. The tool can accept one or more inputs. You will notice the prompt is very basic. The tool options along with their inputs will be passed along to OpenAI. This will invoke one tool at a time per response. However, the `AgentType.OPENAI_MULTI_FUNCTIONS` will allow a list of tool invocations to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful AI assistant.\n",
      "Human: {input}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UMThBMgslMQpTWYlDMEWCaM6jyHs\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702246937,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"Google\",\n",
      "          \"arguments\": \"{\\n  \\\"__arg1\\\": \\\"highest priced stock\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 68,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 85\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Google` with `highest priced stock`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mIf you wonder which company has the highest share price in the world, here is the answer. Berkshire Hathaway, the conglomerate headed by legendary investor Warren Buffett, has the most expensive stock in the world, with shares trading at over $400,000 each.\u001b[0m{\n",
      "  \"id\": \"chatcmpl-8UMTjz0zhPsjXn0s3LZjI1nhIv3wz\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702246939,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The highest priced stock is Berkshire Hathaway, with shares trading at over $400,000 each.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 145,\n",
      "    \"completion_tokens\": 21,\n",
      "    \"total_tokens\": 166\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThe highest priced stock is Berkshire Hathaway, with shares trading at over $400,000 each.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The highest priced stock is Berkshire Hathaway, with shares trading at over $400,000 each.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [google_tool]\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "print(agent.agent.prompt.format(agent_scratchpad=[], input=\"{input}\"))\n",
    "agent.run(\"What is the highest priced stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational\n",
    "\n",
    "This agent is similar to other ReAct agents, but this one has a system prompt optimized for conversations. I have included memory, since that is common with coversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "Human: this is the chat history\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> cool_name: useful to determine if a name is cool\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of cool_name\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "{input}\n",
      "Human: this is the scratchpad\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UNfXUkNGjku0O6olO4CUvFWtHJoX\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702251515,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Hello! How can I assist you today?\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 464,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 489\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Hello! How can I assist you today?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UNfYfL5gK6QppHLkaUNPs1MwaAd8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702251516,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"action\\\": \\\"cool_name\\\",\\n    \\\"action_input\\\": \\\"Brian\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 491,\n",
      "    \"completion_tokens\": 18,\n",
      "    \"total_tokens\": 509\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"cool_name\",\n",
      "    \"action_input\": \"Brian\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mYes, this is a cool name\u001b[0m\n",
      "Thought:{\n",
      "  \"id\": \"chatcmpl-8UNfZikgRMrWEMdQZCNXQHeI1FiTj\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702251517,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Yes, Brian is a cool name.\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 597,\n",
      "    \"completion_tokens\": 24,\n",
      "    \"total_tokens\": 621\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Yes, Brian is a cool name.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, Brian is a cool name.'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [CoolNameTool()]\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "print(agent.agent.llm_chain.prompt.format(agent_scratchpad=[HumanMessage(content=\"this is the scratchpad\")], chat_history=[HumanMessage(content=\"this is the chat history\")], input=\"{input}\"))\n",
    "agent.run(\"hello\")\n",
    "agent.run(\"My name is Brian. Is my name cool?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hello'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='My name is Brian. Is my name cool?'),\n",
       "  AIMessage(content='Yes, Brian is a cool name.')]}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can see the history of the conversation from the memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-ask with Search\n",
    "\n",
    "A specialized agent to be used with a search tool. The LLM must not be a chat model but a normal model. The search tool name must be `Intermediate Answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "Question: {input}\n",
      "Are followup questions needed here:{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-8UOJba95Cj4ulYddEI9LCLhzKg0bq\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1702253999,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" No.\\nSo the final answer is: Avatar (2009)\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 409,\n",
      "    \"completion_tokens\": 13,\n",
      "    \"total_tokens\": 422\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m No.\n",
      "So the final answer is: Avatar (2009)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Avatar (2009)'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search tool name must be \"Intermediate Answer\"\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = [Tool.from_function(func=google.run, name=\"Intermediate Answer\", description=\"useful for when you need to ask with search\")]\n",
    "agent = initialize_agent(tools, llm, AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"What is the highest grossing movie of all time?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Document Store\n",
    "\n",
    "Uses Wikipedia to search and retrieve information. Requires the `wikipedia` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
      "Thought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
      "Action: Search[Colorado orogeny]\n",
      "Observation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
      "Thought: It does not mention the eastern sector. So I need to look up eastern sector.\n",
      "Action: Lookup[eastern sector]\n",
      "Observation: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
      "Thought: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
      "Action: Search[High Plains]\n",
      "Observation: High Plains refers to one of two distinct land regions\n",
      "Thought: I need to instead search High Plains (United States).\n",
      "Action: Search[High Plains (United States)]\n",
      "Observation: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\n",
      "Thought: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
      "Action: Finish[1,800 to 7,000 ft]\n",
      "\n",
      "Question: Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
      "Thought: The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
      "Action: Search[Milhouse]\n",
      "Observation: Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
      "Thought: The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
      "Action: Lookup[named after]\n",
      "Observation: (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
      "Thought: Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
      "Action: Finish[Richard Nixon]\n",
      "\n",
      "Question: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
      "Thought: I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.\n",
      "Action: Search[Adam Clayton Powell]\n",
      "Observation: Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell III’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office Building’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell (film)’, ’Giancarlo Esposito’].\n",
      "Thought: To find the documentary, I can search Adam Clayton Powell (film).\n",
      "Action: Search[Adam Clayton Powell (film)]\n",
      "Observation: Adam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the rise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the PBS series The American Experience.\n",
      "Thought: Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.\n",
      "Action: Finish[The Saimaa Gesture]\n",
      "\n",
      "Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
      "Thought: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
      "Action: Search[Nicholas Ray]\n",
      "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
      "Thought: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
      "Action: Search[Elia Kazan]\n",
      "Observation: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
      "Thought: Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
      "Action: Finish[director, screenwriter, actor]\n",
      "\n",
      "Question: Which magazine was started first Arthur’s Magazine or First for Women?\n",
      "Thought: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
      "Action: Search[Arthur’s Magazine]\n",
      "Observation: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
      "Thought: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
      "Action: Search[First for Women]\n",
      "Observation: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
      "Thought: First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.\n",
      "Action: Finish[Arthur’s Magazine]\n",
      "\n",
      "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "Thought: I need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n",
      "Action: Search[Pavel Urysohn]\n",
      "Observation: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
      "Thought: Pavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n",
      "Action: Search[Leonid Levin]\n",
      "Observation: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
      "Thought: Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
      "Action: Finish[yes]\n",
      "\n",
      "\n",
      "Question: {input}\n",
      "{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-8UOkRvEOrRDtimHJ72l8Qv6RDuZXN\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1702255663,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"Thought: I need to search US presidents, find their ages, then find the youngest one.\\nAction: Search[US presidents]\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1468,\n",
      "    \"completion_tokens\": 28,\n",
      "    \"total_tokens\": 1496\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search US presidents, find their ages, then find the youngest one.\n",
      "Action: Search[US presidents]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mCould not find [US presidents]. Similar: ['List of presidents of the United States', 'Historical rankings of presidents of the United States', 'List of presidents of the United States by age', 'President of the United States', 'List of vice presidents of the United States', 'Heights of presidents and presidential candidates of the United States', 'George Washington', 'List of presidents of the United States by home state', 'Vice President of the United States', 'List of presidents of the United States by net worth']\u001b[0m\n",
      "Thought:{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-8UOkSe5hjJNEmlmWFihxs2ZmGHFJR\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1702255664,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" To find the youngest US president, I can search List of presidents of the United States by age.\\nAction: Search[List of presidents of the United States by age]\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1610,\n",
      "    \"completion_tokens\": 35,\n",
      "    \"total_tokens\": 1645\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m To find the youngest US president, I can search List of presidents of the United States by age.\n",
      "Action: Search[List of presidents of the United States by age]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn this list of presidents of the United States by age, the first table charts the age of each president of the United States at the time of presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan and post-presidency timespan are calculated up to December 11, 2023.\u001b[0m\n",
      "Thought:{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-8UOkUY0VApoXlh9MQyZAUzdtmLpjB\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1702255666,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" The list shows that the youngest US president is John F. Kennedy, who was 43 years old at the time of his inauguration.\\nAction: Finish[John F. Kennedy]\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1732,\n",
      "    \"completion_tokens\": 36,\n",
      "    \"total_tokens\": 1768\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m The list shows that the youngest US president is John F. Kennedy, who was 43 years old at the time of his inauguration.\n",
      "Action: Finish[John F. Kennedy]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'John F. Kennedy'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "  Tool(\n",
    "    name=\"Search\",\n",
    "    func=docstore.search,\n",
    "    description=\"useful for when you need to ask with search\"\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"Lookup\",\n",
    "    func=docstore.lookup,\n",
    "    description=\"useful for when you need to ask with lookup\"\n",
    "  )\n",
    "]\n",
    "agent = initialize_agent(tools, llm, AgentType.REACT_DOCSTORE, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"Who is the youngest US president?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language (LCEL)\n",
    "\n",
    "The agent runtime provided by LangChain is `AgentExecutor`. It does support others runtimes like `Baby AGI` and `Auto GPT`. Up to this point, we have been using predefined agents. Now we will turn to creating our own agents using LCEL. Note, previously we referred to the `AgentExecutor` as `agent`, but here we refer to the `RunnableSequence` or `chain` as the `agent`, which is given to the `AgentExecutor` runtime.\n",
    "\n",
    "1. Building an agent starts with a LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8UP7sEDN4p4d5H679NQZx0dDzHuXf\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702257116,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I am an AI language model developed by OpenAI. I am designed to assist with answering questions and engaging in conversations on a wide range of topics.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"completion_tokens\": 30,\n",
      "    \"total_tokens\": 41\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an AI language model developed by OpenAI. I am designed to assist with answering questions and engaging in conversations on a wide range of topics.')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Then we have tools, which is the same as we have seen before, but let's define one again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def is_number_even(number: int) -> bool:\n",
    "  \"\"\"Returns true if number is even.\"\"\"\n",
    "  return number % 2 == 0\n",
    "\n",
    "tools = [is_number_even]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, we have the prompt. When using OpenAI the prompt is simple, but if using another API the prompt may need more instructions and examples. Let's create a prompt for OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful AI assistant.\n",
      "Human: {input}\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\n",
    "    \"system\",\n",
    "    \"You are a helpful AI assistant.\"\n",
    "  ),\n",
    "  (\"user\", \"{input}\"),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "print(prompt.format(input=\"{input}\", agent_scratchpad=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The next step is to make the LLM aware of the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"is_number_even\",\n",
      "  \"description\": \"is_number_even(number: int) -> bool - Returns true if number is even.\",\n",
      "  \"parameters\": {\n",
      "    \"title\": \"is_number_evenSchemaSchema\",\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"number\": {\n",
      "        \"title\": \"Number\",\n",
      "        \"type\": \"integer\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"number\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openai_tools = [format_tool_to_openai_function(t) for t in tools]\n",
    "llm_with_tools = llm.bind(functions=openai_tools)\n",
    "print(json.dumps(openai_tools[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Then we need to create the agent using the variables from the previous steps to create a `RunnableSequence` using LCEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "agent = (\n",
    "  {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    "  }\n",
    "  | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "print(type(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8UQSZYEBAJ8XMx52S7Fv8nDuRq6fY\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702262243,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"is_number_even\",\n",
      "          \"arguments\": \"{\\n  \\\"number\\\": 4\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 71,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 87\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='is_number_even', tool_input={'number': 4}, log=\"\\nInvoking: `is_number_even` with `{'number': 4}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"number\": 4\\n}', 'name': 'is_number_even'}})])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the AgentAction response from using the agent\n",
    "agent.invoke({\"input\": \"Is 4 an even number?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Right now we just have a runnable sequence, but the agent still doesn't have the ability to iteratively talk to the LLM until the question is answered. There are multiple ways to do this. First, we'll look at the manual way which demonstrates how it works, but keep in mind this will be more easily done soon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8UQmwS7dGSASMpcn47rhCbK39El8Q\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702263506,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"is_number_even\",\n",
      "          \"arguments\": \"{\\n  \\\"number\\\": 343565\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 72,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 89\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UQmxIqDKGY9zvCPYG3l7YyVaYuiU\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702263507,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"No, 343565 is not an even number.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 99,\n",
      "    \"completion_tokens\": 12,\n",
      "    \"total_tokens\": 111\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "No, 343565 is not an even number.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Is 343565 an even number?\"\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "  output: AgentAction = agent.invoke({\"input\": user_input, \"intermediate_steps\": intermediate_steps})\n",
    "  if isinstance(output, AgentFinish):\n",
    "    final_result = output.return_values[\"output\"]\n",
    "    break # we have the final answer\n",
    "  else:\n",
    "    tool: Tool = {\"is_number_even\": is_number_even}[output.tool] # we could have simply called the tool directly\n",
    "    tool_result = tool.run(output.tool_input) # AgentAction knows the tool input\n",
    "    intermediate_steps.append((output, tool_result))\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply this process by using the `AgentExecutor` (the runtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UQqg8pwH1eMLQHheiQts99SD8Msy\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702263738,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"is_number_even\",\n",
      "          \"arguments\": \"{\\n  \\\"number\\\": 4\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 71,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 87\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `is_number_even` with `{'number': 4}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTrue\u001b[0m{\n",
      "  \"id\": \"chatcmpl-8UQqgfHxHfjHMoJDbavSSf6rKGpW3\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702263738,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Yes, 4 is an even number.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 97,\n",
      "    \"completion_tokens\": 10,\n",
      "    \"total_tokens\": 107\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mYes, 4 is an even number.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is 4 an even number?', 'output': 'Yes, 4 is an even number.'}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_runtime = AgentExecutor(agent=agent, tools=tools, verbose=True) # similar to initialize_agent but we provide the custom agent\n",
    "agent_runtime.invoke({\"input\": \"Is 4 an even number?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (Optional) We can also give the agent memory if we want a more conversational approach. This requires us to change the `prompt` and `agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_key = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\n",
    "    \"system\",\n",
    "    \"You are a helpful AI assistant.\"\n",
    "  ),\n",
    "  MessagesPlaceholder(variable_name=memory_key), # this is needed to hold the history of the conversation\n",
    "  (\"user\", \"{input}\"),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "  {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]),\n",
    "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
    "  }\n",
    "  | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_runtime = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UR1rd6cLQM7yBQuNY6qgmlhkhFu3\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702264431,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"is_number_even\",\n",
      "          \"arguments\": \"{\\n  \\\"number\\\": 34234\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 72,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 89\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `is_number_even` with `{'number': 34234}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTrue\u001b[0m{\n",
      "  \"id\": \"chatcmpl-8UR1rwYsjAC6eSaf6o7fSrtqpDfZ5\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702264431,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Yes, 34234 is an even number.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 99,\n",
      "    \"completion_tokens\": 11,\n",
      "    \"total_tokens\": 110\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mYes, 34234 is an even number.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UR1s4PqfX4EuvJmk3SNaluBsHbWM\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702264432,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"is_number_even\",\n",
      "          \"arguments\": \"{\\n  \\\"number\\\": 1\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 97,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 113\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `is_number_even` with `{'number': 1}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mFalse\u001b[0m{\n",
      "  \"id\": \"chatcmpl-8UR1tRDwQqB7gU7oEDfccCI4I4r2o\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702264433,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"No, 1 is not an even number.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 123,\n",
      "    \"completion_tokens\": 11,\n",
      "    \"total_tokens\": 134\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mNo, 1 is not an even number.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "input1 = \"is 34234 an even number?\"\n",
    "input2 = \"is 1 an even number?\"\n",
    "result1 = agent_runtime.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "  HumanMessage(content=input1),\n",
    "  AIMessage(content=result1[\"output\"])\n",
    "])\n",
    "result2 = agent_runtime.invoke({\"input\": input2, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "  HumanMessage(content=input2),\n",
    "  AIMessage(content=result2[\"output\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.human.HumanMessage'> is 34234 an even number?\n",
      "<class 'langchain_core.messages.ai.AIMessage'> Yes, 34234 is an even number.\n",
      "<class 'langchain_core.messages.human.HumanMessage'> is 1 an even number?\n",
      "<class 'langchain_core.messages.ai.AIMessage'> No, 1 is not an even number.\n"
     ]
    }
   ],
   "source": [
    "for c in chat_history:\n",
    "  print(type(c), c.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
