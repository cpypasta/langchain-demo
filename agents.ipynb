{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, openai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import Tool, tool, load_tools, initialize_agent, AgentType, AgentExecutor\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
    "from langchain.docstore import Wikipedia\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools.render import render_text_description, format_tool_to_openai_function\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.schema.agent import AgentFinish, AgentAction\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gpt3_5 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The tools are functionality that agents can use to perform their tasks.\n",
    "\n",
    "> Note: Only LLMs that support function calling can use tools from a function. At this time, OpenAI provides the most support.\n",
    "\n",
    "> TODO: Demonstrate using a local LLM with tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain has some easy Tool wrappers for some tools\n",
    "google = GoogleSerperAPIWrapper()\n",
    "google_tool = Tool.from_function(\n",
    "  func=google.run,\n",
    "  name=\"Google\",\n",
    "  description=\"useful for when you need search for something you are not sure about\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ingredients ; 1 cup white sugar ; ½ cup unsalted butter ; 2 large eggs ; 2 teaspoons vanilla extract ; 1 ½ cups all-purpose flour. How to make vanilla cake. 1. Whip the eggs and sugar – Beat the eggs ... How to make vanilla cake. 2. Gradually add flour – Whisk together the ... cake in 2 minutes! you will make this cake every day! easy and quick to prepare. very ... Duration: 3:37. Posted: Jul 17, 2022. Easy to adjust Vanilla Cake to make vanilla cupcakes, birthday cake, vanilla sheet cakes and ... Duration: 5:12. Posted: Sep 21, 2023. How to Bake a Cake · Step 13: Frost and Decorate · Step 12: Add a Crumb Coat · Step 11: Assemble the Cake · Step 10: Cool the Cake Layers · Step 9: Check Cake ... Ingredients ; cooking spray ; 2 ⅔ · all-purpose flour, or more as needed ; 1 · white sugar ; 1 · baking powder ; 1 · vanilla extract. A classic vanilla cake recipe is often simple and beginner-friendly. Combine flour, sugar, butter, eggs, milk, and vanilla extract. Make the cake: Whisk the cake flour, salt, baking powder, and baking soda together. · Make the frosting: In a large bowl using a handheld mixer ... 8. Divide cake batter between two (8 or 9″) round baking pans, as evenly as possible, smooth the tops and bake on the middle rack in ... Whisk 3 cups flour, the baking powder and salt in a bowl until combined. Beat 2 sticks butter and the sugar in a large bowl with a mixer on medium-high speed ...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can simply invoke\n",
    "google_tool.invoke(\"how to make a cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using decorator\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "  \"\"\"Returns the length of a word.\"\"\"\n",
    "  return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support for multi input data structures\n",
    "class Word(BaseModel):\n",
    "  word: str = Field()\n",
    "  strategy: str = Field()\n",
    "  \n",
    "def word_length(word: str, strategy: str) -> int:\n",
    "  return len(word) if strategy == \"normal\" else len(word) * 2\n",
    "\n",
    "word_tool = StructuredTool.from_function(\n",
    "  func=word_length,\n",
    "  name=\"Word_Length_Calculator\",\n",
    "  description=\"useful to calculate the length of a word. use strategy='normal' for normal length, strategy='turbo' for turbo length.\",\n",
    "  args_schema=Word\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolNameTool(BaseTool):\n",
    "  name = \"cool_name\"\n",
    "  description = \"useful to determine if a name is cool\"\n",
    "  \n",
    "  def _run(self, query: str) -> str:\n",
    "    return \"Yes, this is a cool name\" if query == \"Brian\" else \"No, this is not a cool name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  Tool(\n",
    "    name=\"Search\",\n",
    "    func=google.run,\n",
    "    description=\"useful for when you need information about current events and data\"\n",
    "  ),\n",
    "  word_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_text_description(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Agents\n",
    "\n",
    "Every agent type in `langchain` has different characteristics, but they mainly differ in what prompt they are using and how they determine what tools to use. It will use either `ReAct` from langchain or `OpenAI` to manage tool invocations. We will first look at the available `off-the-shelf agent` options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot ReAct\n",
    "Uses the ReAct framework to determine which tool to use based solely on the tool's description. A very general purpose action agent. ONLY supports tools with single string input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can load builtin tools from langchain.agents\n",
    "tools = load_tools([\"llm-math\"], gpt3_5)\n",
    "# will create simple AgentExecutor (no prompt or pipeline)\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"What is 25 to the power of 0.43 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Input ReAct (Structured Chat)\n",
    "\n",
    "Just like zero-shot but supports multi-input tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [word_tool]\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.format(agent_scratchpad=\"{agent_scratchpad}\", input=\"{input}\"))\n",
    "agent.run(\"What is the length of the word 'boulder'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "This agent will let OpenAI make the decision on what tool to use. The tool can accept one or more inputs. You will notice the prompt is very basic. The tool options along with their inputs will be passed along to OpenAI. This will invoke one tool at a time per response. However, the `AgentType.OPENAI_MULTI_FUNCTIONS` will allow a list of tool invocations to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [google_tool]\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "print(agent.agent.prompt.format(agent_scratchpad=[], input=\"{input}\"))\n",
    "agent.run(\"What is the highest priced stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational\n",
    "\n",
    "This agent is similar to other ReAct agents, but this one has a system prompt optimized for conversations. I have included memory, since that is common with coversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CoolNameTool()]\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent = initialize_agent(tools, gpt3_5, AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "print(agent.agent.llm_chain.prompt.format(agent_scratchpad=[HumanMessage(content=\"this is the scratchpad\")], chat_history=[HumanMessage(content=\"this is the chat history\")], input=\"{input}\"))\n",
    "agent.run(\"hello\")\n",
    "agent.run(\"My name is Brian. Is my name cool?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see the history of the conversation from the memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-ask with Search\n",
    "\n",
    "A specialized agent to be used with a search tool. The LLM must not be a chat model but a normal model. The search tool name must be `Intermediate Answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tool name must be \"Intermediate Answer\"\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = [Tool.from_function(func=google.run, name=\"Intermediate Answer\", description=\"useful for when you need to ask with search\")]\n",
    "agent = initialize_agent(tools, llm, AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"What is the highest grossing movie of all time?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Document Store\n",
    "\n",
    "Uses Wikipedia to search and retrieve information. Requires the `wikipedia` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "  Tool(\n",
    "    name=\"Search\",\n",
    "    func=docstore.search,\n",
    "    description=\"useful for when you need to ask with search\"\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"Lookup\",\n",
    "    func=docstore.lookup,\n",
    "    description=\"useful for when you need to ask with lookup\"\n",
    "  )\n",
    "]\n",
    "agent = initialize_agent(tools, llm, AgentType.REACT_DOCSTORE, verbose=True)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "agent.run(\"Who is the youngest US president?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agent\n",
    "\n",
    "The agent runtime provided by LangChain is `AgentExecutor`. It does support others runtimes like `Baby AGI` and `Auto GPT`. Up to this point, we have been using predefined agents. Now we will turn to creating our own agents.\n",
    "\n",
    "1. Building an agent starts with a LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Then we have tools, which is the same as we have seen before, but let's define one again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def is_number_even(number: int) -> bool:\n",
    "  \"\"\"Returns true if number is even.\"\"\"\n",
    "  return number % 2 == 0\n",
    "\n",
    "tools = [is_number_even]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, we have the prompt. When using OpenAI the prompt is simple, but if using another API the prompt may need more instructions and examples. Let's create a prompt for OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\n",
    "    \"system\",\n",
    "    \"You are a helpful AI assistant.\"\n",
    "  ),\n",
    "  (\"user\", \"{input}\"),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "print(prompt.format(input=\"{input}\", agent_scratchpad=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The next step is to make the LLM aware of the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_tools = [format_tool_to_openai_function(t) for t in tools]\n",
    "llm_with_tools = llm.bind(functions=openai_tools)\n",
    "print(json.dumps(openai_tools[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Then we need to create the chain using the variables from the previous steps to create a `RunnableSequence`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "  {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    "  }\n",
    "  | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the AgentAction response from using the chain\n",
    "chain.invoke({\"input\": \"Is 4 an even number?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Right now we just have a runnable sequence (i.e., chain), but the chain still doesn't have any dynamic capability. There are multiple ways to do this. First, we'll look at the hard way which demonstrates the process, but keep in mind this can be simplified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Is 343565 an even number?\"\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "  output: AgentAction = chain.invoke({\"input\": user_input, \"intermediate_steps\": intermediate_steps})\n",
    "  if isinstance(output, AgentFinish):\n",
    "    final_result = output.return_values[\"output\"]\n",
    "    break # we have the final answer\n",
    "  else:\n",
    "    tool: Tool = {\"is_number_even\": is_number_even}[output.tool] # we could have simply called the tool directly\n",
    "    tool_result = tool.run(output.tool_input) # AgentAction knows the tool input\n",
    "    intermediate_steps.append((output, tool_result))\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply this process by using the `AgentExecutor` (the runtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentExecutor(agent=chain, tools=tools, verbose=True) # similar to initialize_agent but we provide the custom agent\n",
    "agent.invoke({\"input\": \"Is 4 an even number?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (Optional) We can also give the agent memory if we want a more conversational approach. This requires us to change the `prompt` and `agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_key = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\n",
    "    \"system\",\n",
    "    \"You are a helpful AI assistant.\"\n",
    "  ),\n",
    "  MessagesPlaceholder(variable_name=memory_key), # this is needed to hold the history of the conversation\n",
    "  (\"user\", \"{input}\"),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "  {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]),\n",
    "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
    "  }\n",
    "  | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentExecutor(agent=chain, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "input1 = \"is 34234 an even number?\"\n",
    "input2 = \"is 1 an even number?\"\n",
    "result1 = agent.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "  HumanMessage(content=input1),\n",
    "  AIMessage(content=result1[\"output\"])\n",
    "])\n",
    "result2 = agent.invoke({\"input\": input2, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "  HumanMessage(content=input2),\n",
    "  AIMessage(content=result2[\"output\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in chat_history:\n",
    "  print(type(c), c.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Assistants\n",
    "\n",
    "OpenAI assistants are agents and can have tools of its own, which then can be in turn combined with functional tool defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_assitant = OpenAIAssistantRunnable.create_assistant(\n",
    "  name=\"language translator\",\n",
    "  instructions=\"You are a language translator. Translate the user text from English into whatever language is requsted\",\n",
    "  tools=[],\n",
    "  model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "output = translator_assitant.invoke({\n",
    "  \"content\": \"'Suck on my dongle' to Spanish\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_bYKqzdRLtpe5R19FSvM1zHKd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Chúpame el dongle\" in Spanish.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_id = translator_assitant.assistant_id\n",
    "print(assistant_id)\n",
    "output[0].content[0].text.value # ThreadMessage: very nested structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_assitant.as_agent = True\n",
    "agent = AgentExecutor(agent=translator_assitant, tools=[]) # can be combined with local tools\n",
    "output = agent.invoke({\n",
    "  \"content\": \"'Suck on my dongle' to German\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"'Suck on my dongle' to German\", 'output': '\"Leck meinen Dongle\" in German.', 'thread_id': 'thread_I1CAzbl9hPnYqLENnKwYeD85', 'run_id': 'run_AAzDYuz8KHsFtxHKtl6kaKAu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Leck meinen Dongle\" in German.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"output\"] # basic dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use an existing assistant as an agent with LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_assistant = OpenAIAssistantRunnable(assistant_id=assistant_id, as_agent=True)\n",
    "output = existing_assistant.invoke({ \"content\": \"'hello' to Spanish\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.agents.openai_assistant.base.OpenAIAssistantFinish'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'hola'\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(output))\n",
    "output.return_values[\"output\"] # child of AgentAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Client().beta.assistants.delete(assistant_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
