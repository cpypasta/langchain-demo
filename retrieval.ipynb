{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is the process of inluding data in the prompt to the LLM that was was not part of the language model training data. The overall process looks like:\n",
    "\n",
    "![flow](https://python.langchain.com/assets/images/data_connection-95ff2033a8faa5f3ba41376c0f6dd32a.jpg)\n",
    "\n",
    "The components of the RAG process:\n",
    "1. Document Loaders\n",
    "2. Document Transformers\n",
    "3. Text Embedding Models\n",
    "4. Vector Stores\n",
    "5. Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loaders\n",
    "\n",
    "These load documents from many different sources. The simpliest type of loader is `TextLoader`, which loads an entire file as a single document. The rest are common loaders you will commonly need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import (\n",
    "  TextLoader, \n",
    "  DirectoryLoader, \n",
    "  UnstructuredHTMLLoader, \n",
    "  JSONLoader,\n",
    "  UnstructuredMarkdownLoader,\n",
    "  PyPDFLoader,\n",
    "  AsyncHtmlLoader,\n",
    "  WebBaseLoader\n",
    ")\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextLoader(\"./data/data.txt\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVLoader(\"./data/data.csv\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirectoryLoader(\"./data/\", glob=\"*.txt\", loader_cls=TextLoader).load() # you can pick the loader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnstructuredHTMLLoader(\"./data/data.html\").load() # will strip markup and load just the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONLoader(file_path=\"./data/data.json\", jq_schema=\".data[].name\").load() # returns text not json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnstructuredMarkdownLoader(\"./data/data.md\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPDFLoader(\"./data/data.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPDFLoader(\"./data/data_long.pdf\").load_and_split() # uses RecursiveCharacterTextSplitter to split the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://shop.deere.com/us/product/Sherpa-Full-Zip-Jacket/p/SCUALC0593\"\n",
    "loader = AsyncHtmlLoader([url])\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(url) # a combination of a AsyncHtmlLoader and Html2TextLoader\n",
    "docs = loader.load() # there is also a loader.aload() for asyncronous loading\n",
    "print(docs[0].metadata)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Transformers\n",
    "\n",
    "After loading your documents, you will often want to transform them. The most common transformation is splitting the document into smaller chunks. Here are some common transformations:\n",
    "\n",
    "1. Text splitting\n",
    "2. Content Transformation\n",
    "3. Extract Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.document_transformers.openai_functions import create_metadata_tagger\n",
    "from langchain.document_transformers import Html2TextTransformer, BeautifulSoupTransformer\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import AnalyzeDocumentChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Splitting\n",
    "\n",
    "The most common text splitter is `RecursiveCharacterTextSplitter` which splits larger documents into smaller documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=100, # maximium number of characters in a chunk (default: 4000)\n",
    "  chunk_overlap=20 # overlap between chunks to maintain context in each chunk (default: 200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.split_documents(TextLoader(\"./data/sotu.txt\").load())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also be used directly on text\n",
    "RecursiveCharacterTextSplitter(chunk_size=3, chunk_overlap=1).split_text(\"this is some text 1 2 3 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple `CharacterTextSplitter` that doesn't use multiple separators to split the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharacterTextSplitter(\n",
    "  separator=\"#ENTRY\",\n",
    "  chunk_size=10, # you will notice that the entries are still in their own document \n",
    "  chunk_overlap=5\n",
    ").split_documents(TextLoader(\"./data/data_split.txt\").load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://shop.deere.com/us/product/Sherpa-Full-Zip-Jacket/p/SCUALC0593\"\n",
    "loader = AsyncHtmlLoader(url)\n",
    "docs = loader.load()\n",
    "Html2TextTransformer().transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AsyncHtmlLoader(url)\n",
    "docs = loader.load()\n",
    "BeautifulSoupTransformer().transform_documents(\n",
    "  docs,\n",
    "  tags_to_extract=[\"main\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize\n",
    "\n",
    "There are a few ways to summarize documents:\n",
    "\n",
    "1. `stuff`: All the documents will be put together and summarized by the LLM.\n",
    "2. `map_reduce`: Each document will be summarized by the LLM, and the then the LLM will summarize the summaries.\n",
    "3. `refine`: Will iterate over each document refining the summary until there are no more documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherpa = \"https://shop.deere.com/us/product/Sherpa-Full-Zip-Jacket/p/SCUALC0593\"\n",
    "puffer = \"https://shop.deere.com/us/product/Puffer-Jacket/p/SCUFLC0082\"\n",
    "loader = AsyncHtmlLoader([sherpa, puffer])\n",
    "docs = loader.load()\n",
    "transformed_docs = BeautifulSoupTransformer().transform_documents(\n",
    "  docs,\n",
    "  tags_to_extract=[\"main\"]\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(transformed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "chain.run(transformed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "chain.run(transformed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need more control over the summary prompt, you can provide your own like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "Write a concise summary of the following, but DO NOT explicitly say it is a summary:\n",
    "\"{text}\"\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(summary_template)\n",
    "stuff_chain = load_summarize_chain(llm, \"stuff\", prompt=prompt)\n",
    "stuff_chain.run(transformed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "Write a concise summary of the following, but DO NOT explicitly say it is a summary:\n",
    "\"{text}\"\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(summary_template)\n",
    "summary_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=summary_chain, document_variable_name=\"text\")\n",
    "stuff_chain.run(transformed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a special chain that can summarize some arbitrary text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "analyze_chain = AnalyzeDocumentChain(combine_docs_chain=chain, text_splitter=text_splitter)\n",
    "analyze_chain.run(transformed_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for relevant documents can be greatly improved with the proper metadata associated with the text itself. There are a couple ways that you can add metadata with LangChain.\n",
    "\n",
    "The first way is by using `OpenAI` functions, which tries to extract the metadata for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can define the schema with a dict or a pydantic model\n",
    "schema = {\n",
    "  \"properties\": {\n",
    "      \"category\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"the high-level category of the food being discussed like 'fruit' or 'vegetable' or snack\"\n",
    "      },\n",
    "      \"tone\": {\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"positive\", \"negative\"],\n",
    "        \"description\": \"the tone of the text like 'positive' or 'negative'\"\n",
    "      }\n",
    "  },\n",
    "  \"required\": [\"category\", \"tone\"],\n",
    "}\n",
    "llm = ChatOpenAI()\n",
    "document_transformer = create_metadata_tagger(llm=llm, metadata_schema=schema) # can provide prompt if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_documents = [\n",
    "  Document(page_content=\"The apples I ate were delicious.\"),\n",
    "  Document(page_content=\"The pizza tasted like crap.\"),\n",
    "]\n",
    "enhanced_documents = document_transformer.transform_documents(org_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
